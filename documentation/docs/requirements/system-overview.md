---
sidebar_position: 1
---

# System Overview

## Project Abstract

This document proposes an application programming interface (API) that supports AAC games. The API will allow users to play AAC games like StoryQuest through external AAC board interaction, rather than being forced to rely on an embedded AAC board in the game. Users can relay game inputs by either speaking with their mouths or speaking through their AAC board. The API will enable audio-controlled games, which will provide support social and communication skills in children who use AAC devices by further enabling AAC users to play games alongside non-AAC users.

## Conceptual Design

Our proposed solution is a client side JS API designed for integration into existing and newly developed web based AAC Board designed games. The core of the API will leverage standard browser tech, making sure that we have broad compatibility and not having the brunt of service side processing or cloud expenses. The tool for converting the audio from an AAC device into text will be the Web Speech API, which is natively supported by most browsers. To address the challenge of voice isolation in potential noisy environments like a clinic, we will process the audio from the microphone before it reaches the transcription API. This will be accomplished using Web Audio API which allows you to work with audio streams. Next it would pass through RNNoise which allows for client side noise suppression which would help eliminate ambient noise and other voices from the one we actually want to hear. The API will be structured to be highly reusable, a game developer will simply include/import our script and initialize it with a  config object that would act as a user defined “dictionary” of specific spoken words or phrases (eg “jump”, “start game”) that maps to callback functions. This would allow developers to easily add AAC device compatibility without modifying their core game logic.

## Background

Augmentative and Alternative Communication (AAC) devices are essential tools that provide a voice to individuals with significant speech impairments, these stem from conditions like autism spectrum disorder, cerebral palsy, or ALS. These devices allow users to express their needs, thoughts, feelings, and much more. However, while very effective for communication, their use in dynamic, fast paced environments like video games is all but none. This often can lead to a frustrating experience or social exclusion. The goal is to make games with these users in mind to help foster the idea of being able to fit in and not have to put the AAC device down. Our project aims to bridge the gap by creating an API that would allow users to participate in web based games using their AAC device that they are already comfortable and proficient with. The current approach within this target of games is using a simulated AAC board on a secondary device, like an iPad. While this is a functional solution, it forces users to learn a new, game specific interface rather than using their already familiar device. This project directly improves upon that model by allowing for direct input from the user's own device. Other projects like the reimagined Hungry Hungry Hippo game, have successfully created a new experience for AAC users. These are valuable contributions but often give developers of these games extra work and development cycles to implement a board into their games. Rather than building a new game, we are creating a reusable and universal tool that any developer can use to easily integrate into their existing or future web games. Our API is being specifically designed to solve the difficult problem of isolating an AAC voice from the background noise of a clinic or classroom, making it an application of voice recognition technology aimed squarely at allowing AAC users to play how they most comfortably can. 
