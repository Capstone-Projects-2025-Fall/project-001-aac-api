"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[3153],{28453:(n,e,a)=>{a.d(e,{R:()=>t,x:()=>s});var i=a(96540);const o={},r=i.createContext(o);function t(n){const e=i.useContext(r);return i.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:t(n.components),i.createElement(r.Provider,{value:e},n.children)}},63592:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>c,contentTitle:()=>s,default:()=>l,frontMatter:()=>t,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"system-architecture/class-diagram","title":"Class Diagram","description":"This diagram illustrates the core architecture of AAC Voice API, showing the relationships between main classes","source":"@site/docs/system-architecture/class-diagram.md","sourceDirName":"system-architecture","slug":"/system-architecture/class-diagram","permalink":"/project-001-aac-api/docs/system-architecture/class-diagram","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/edit/main/documentation/docs/system-architecture/class-diagram.md","tags":[],"version":"current","lastUpdatedBy":"Gino Russo","frontMatter":{"title":"Class Diagram"},"sidebar":"docsSidebar","previous":{"title":"Version Control","permalink":"/project-001-aac-api/docs/system-architecture/version-control"},"next":{"title":"Test Procedures","permalink":"/project-001-aac-api/docs/category/test-procedures"}}');var o=a(74848),r=a(28453);const t={title:"Class Diagram"},s="Class Diagram",c={},d=[{value:"index",id:"index",level:3},{value:"AACVoiceApi",id:"aacvoiceapi",level:3},{value:"SpeechConverter",id:"speechconverter",level:3},{value:"CommandHistory",id:"commandhistory",level:3},{value:"commandLibrary",id:"commandlibrary",level:3},{value:"AudioInputHandler",id:"audioinputhandler",level:3},{value:"showHistoryPopup",id:"showhistorypopup",level:3},{value:"SpeechToText",id:"speechtotext",level:3},{value:"CommandMapper",id:"commandmapper",level:3},{value:"SpeechSeparation",id:"speechseparation",level:3},{value:"Key Relationships",id:"key-relationships",level:3}];function m(n){const e={code:"code",h1:"h1",h3:"h3",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"class-diagram",children:"Class Diagram"})}),"\n",(0,o.jsx)(e.p,{children:"This diagram illustrates the core architecture of AAC Voice API, showing the relationships between main classes\nand their responsibilities"}),"\n",(0,o.jsx)(e.mermaid,{value:"classDiagram\n    class index {\n        + AACVoiceApi: AACVoiceApi\n    }\n\n    class AACVoiceApi {\n        - converter: SpeechConverter\n        \n        + initiate(url: String, language: String) : void\n        + start() : void\n        + stop() : void\n        + displayCommandHistory() : void\n    }\n\n    class AudioInputHandler {\n        - stream: MediaStream\n        - ctx: AudioContext\n        - processor: ScriptProcessorNode\n        + isListening: Boolean\n        \n        + onAudioChunk(chunk: Float32Array) void\n        + getSampleRate() number\n        + startListening() Promise~void~\n        + stopListening() void\n    }\n    \n    class CommandHistory {\n        - history: string[]\n        - enabled: Boolean\n        - instance: CommandHistory$ \n        \n        + getInstance() CommandHistory$\n        + toggle(enable: Boolean) void\n        + add(command: string) void\n        + getAll() string[]\n        + getSize() number\n        + getSlice(start: number, end: number) string[]\n        + clear() void\n    }\n    \n    class CommandLogEntry {\n        <<interface>>\n        + timestamp: Date\n        + commandName: string\n        + status: string\n    }\n    CommandHistory ..|> CommandLogEntry\n    \n    class GameCommand {\n     <<interface>>\n     + name: string\n     + description: string\n     + active: Boolean\n     \n     + action() void\n    }\n    \n    class commandLibrary {\n        - commandMap: Map<string, GameCommand>\n        - instance: CommandLibrary$\n        \n        + getInstance() CommandLibrary$\n        - normalize(name: string) string\n        + add(command: GameCommand) Boolean\n        + remove(name: string) Boolean\n        + has(name: string) Boolean\n        + get(name: string) Boolean\n        + list() GameCommand[]\n        + clear() void\n    }\n    commandLibrary ..|> GameCommand\n    \n    class CommandMapping {\n        - library: CommandLibrary\n        \n        - normalize(name: string) string\n        + addCommand(name: string, action() void, options(description: string, active: Boolean)) Boolean\n        + removeCommand(name: string) Boolean\n        + getAllCommands() string[]\n        + hasCommand(name: string) Boolean\n        + getCommand(name: string) GameCommand | undefined\n        + clearAllCommands() void\n    }\n    \n    class showHistoryPopup {\n        - commandHistory: CommandHistory\n        \n        + showHistoryPopup() void\n    }\n    \n    class SpeechConverter {\n        - whisper: WhisperModule | null\n        - audioHandler: AudioInputHandler | null\n        - transcribedText: CommandHistory | null\n        - transcriptionInterval: ReturnType<setInterval>\n        \n        - loadModelToFS(modelPath: string) Promise~string~\n        + init(modelPath: string, lang: string) Promise~void~\n        - downSample(input: Float32Array, inputRate: number, outputRate: number) Float32Array\n        - combineChunks(buffer: Float32Array[], blockSize: number) Float32Array\n        + startListening() void\n        + stopListening() void\n        - setAudio(index: number, audio: Float32Array) number\n        + getTranscribed() string\n        + getStatus() string\n        + createWhisperModule() Promise~WhisperModule~\n    }\n    \n    class WhisperModule {\n        <<interface>>\n    }\n    SpeechConverter ..|> WhisperModule\n    class SpeechToText {\n        \n    }\n    \n    class CommandConverter {\n        - library: CommandLibrary\n        - commandHistory: CommandHistory\n        - instance: CommandConverter$\n        \n        - onCommandMatched(commands: GameCommand[], transcription: string) void\n        + getInstance() CommandConverter$\n        - normalize(word: string) string\n        - tokenize(transcription: string) string[]\n        + processTranscription(transcription: string) GameCommand[]\n        - logCommand(command: GameCommand, originalText: string, status: string) void\n        \n    }\n    SpeechToText: This class is currently empty.\n    \n    class CommandMapper {\n       \n    }\n    CommandMapper: This class is currently empty.\n\n\n    class SpeechSeparation {\n       \n    }\n    SpeechSeparation: This class is currently empty.\n\n    SpeechConverter ..> AudioInputHandler\n    SpeechConverter ..> CommandHistory\n    showHistoryPopup ..> CommandHistory\n    AACVoiceApi ..> showHistoryPopup\n    AACVoiceApi ..> SpeechConverter\n    CommandMapping ..> commandLibrary\n    CommandConverter ..> commandLibrary\n    CommandConverter ..> CommandHistory\n    AACVoiceApi *-- SpeechToText : contains\n    AACVoiceApi *-- CommandMapper : contains\n    index ..> AACVoiceApi\n    index ..> commandLibrary\n    AudioInputHandler *-- SpeechSeparation : contains"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Figure 2"})," Class Architecture of our API"]}),"\n",(0,o.jsx)(e.h3,{id:"index",children:"index"}),"\n",(0,o.jsxs)(e.p,{children:["This is the main entry point for npm package ",(0,o.jsx)(e.code,{children:"'aac-voice-api'"}),".\nIt exports the core classes, functions, and types that\nmake up the public API of the library."]}),"\n",(0,o.jsx)(e.h3,{id:"aacvoiceapi",children:"AACVoiceApi"}),"\n",(0,o.jsx)(e.p,{children:"The main entry point for the API. This will be a facade and the only class that a developer will have to initialize.\nInitializes voice command recognition and manages the lifecycle of voice listening sessions."}),"\n",(0,o.jsx)(e.h3,{id:"speechconverter",children:"SpeechConverter"}),"\n",(0,o.jsx)(e.p,{children:"Handles real-time speech-to-text conversion using the Whisper model.\nIt manages audio input, preprocessing, and transcription directly in the browser."}),"\n",(0,o.jsx)(e.h3,{id:"commandhistory",children:"CommandHistory"}),"\n",(0,o.jsx)(e.p,{children:"Keeps track of a chronological log of commands."}),"\n",(0,o.jsx)(e.h3,{id:"commandlibrary",children:"commandLibrary"}),"\n",(0,o.jsx)(e.p,{children:"Contains a HashMap that:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Can be called by CommandMapper."}),"\n",(0,o.jsx)(e.li,{children:"Maps a String command to the corresponding GameCommand."}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"audioinputhandler",children:"AudioInputHandler"}),"\n",(0,o.jsx)(e.p,{children:"Handles raw audio stream processing from the user's microphone. Manages Web Audio API components and converts audio into processable chunks."}),"\n",(0,o.jsx)(e.h3,{id:"showhistorypopup",children:"showHistoryPopup"}),"\n",(0,o.jsx)(e.p,{children:"Opens a modal that shows the latest commands and auto-refreshes every second.\nStorage is unbounded; UI renders only a window (latest PAGE items) for speed."}),"\n",(0,o.jsx)(e.h3,{id:"speechtotext",children:"SpeechToText"}),"\n",(0,o.jsx)(e.p,{children:"Consumes (from AudioHandlerInput) and converts audio chunks into text transcriptions for command recognition."}),"\n",(0,o.jsx)(e.h3,{id:"commandmapper",children:"CommandMapper"}),"\n",(0,o.jsx)(e.p,{children:"Maps recognized speech text to configured voice commands and triggers the appropriate functions"}),"\n",(0,o.jsx)(e.h3,{id:"speechseparation",children:"SpeechSeparation"}),"\n",(0,o.jsx)(e.p,{children:"Processes audio to separate speech from background noise, improving recognition accuracy"}),"\n",(0,o.jsx)(e.h3,{id:"key-relationships",children:"Key Relationships"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"AACVoiceApi serves as the orchestrator, containing and coordinating all major components"}),"\n",(0,o.jsx)(e.li,{children:"AudioHandlerInput captures and preprocessors audio before passing it to the speech recognition pipeline"}),"\n"]})]})}function l(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(m,{...n})}):m(n)}}}]);