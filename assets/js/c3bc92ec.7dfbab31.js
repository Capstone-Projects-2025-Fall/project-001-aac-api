"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[9457],{28453:(e,n,r)=>{r.d(n,{R:()=>c,x:()=>a});var t=r(96540);const i={},s=t.createContext(i);function c(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:c(e.components),t.createElement(s.Provider,{value:n},e.children)}},44312:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>c,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"api-specification/classes/SpeechConverterOnline","title":"SpeechConverterOnline","description":"aac-voice-api","source":"@site/docs/api-specification/classes/SpeechConverterOnline.md","sourceDirName":"api-specification/classes","slug":"/api-specification/classes/SpeechConverterOnline","permalink":"/project-001-aac-api/docs/api-specification/classes/SpeechConverterOnline","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/edit/main/documentation/docs/api-specification/classes/SpeechConverterOnline.md","tags":[],"version":"current","lastUpdatedBy":"Gino Russo","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"SpeechConverterOffline","permalink":"/project-001-aac-api/docs/api-specification/classes/SpeechConverterOffline"},"next":{"title":"SynonymResolver","permalink":"/project-001-aac-api/docs/api-specification/classes/SynonymResolver"}}');var i=r(74848),s=r(28453);const c={},a=void 0,l={},o=[{value:"Implements",id:"implements",level:2},{value:"Constructors",id:"constructors",level:2},{value:"Constructor",id:"constructor",level:3},{value:"Parameters",id:"parameters",level:4},{value:"Returns",id:"returns",level:4},{value:"Methods",id:"methods",level:2},{value:"getStatus()",id:"getstatus",level:3},{value:"Returns",id:"returns-1",level:4},{value:"Throws",id:"throws",level:4},{value:"Implementation of",id:"implementation-of",level:4},{value:"getTextLog()",id:"gettextlog",level:3},{value:"Returns",id:"returns-2",level:4},{value:"Implementation of",id:"implementation-of-1",level:4},{value:"getTranscribed()",id:"gettranscribed",level:3},{value:"Returns",id:"returns-3",level:4},{value:"Implementation of",id:"implementation-of-2",level:4},{value:"getUseSeparation()",id:"getuseseparation",level:3},{value:"Returns",id:"returns-4",level:4},{value:"init()",id:"init",level:3},{value:"Parameters",id:"parameters-1",level:4},{value:"Returns",id:"returns-5",level:4},{value:"Implementation of",id:"implementation-of-3",level:4},{value:"startListening()",id:"startlistening",level:3},{value:"Returns",id:"returns-6",level:4},{value:"Throws",id:"throws-1",level:4},{value:"Throws",id:"throws-2",level:4},{value:"Implementation of",id:"implementation-of-4",level:4},{value:"stopListening()",id:"stoplistening",level:3},{value:"Returns",id:"returns-7",level:4},{value:"Implementation of",id:"implementation-of-5",level:4}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/",children:(0,i.jsx)(n.strong,{children:"aac-voice-api"})})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/e7ecee09619c371f2c7a38bb65d9a3fd55a16d86/src/SpeechConverterOnline.ts#L5",children:"SpeechConverterOnline.ts:5"})]}),"\n",(0,i.jsx)(n.h2,{id:"implements",children:"Implements"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface",children:(0,i.jsx)(n.code,{children:"SpeechConverterInterface"})})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"constructors",children:"Constructors"}),"\n",(0,i.jsx)(n.h3,{id:"constructor",children:"Constructor"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"new SpeechConverterOnline(domainName, useSeparation): SpeechConverterOnline;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/e7ecee09619c371f2c7a38bb65d9a3fd55a16d86/src/SpeechConverterOnline.ts#L23",children:"SpeechConverterOnline.ts:23"})]}),"\n",(0,i.jsx)(n.p,{children:"updates the url to point to the correct backend on initialization"}),"\n",(0,i.jsx)(n.h4,{id:"parameters",children:"Parameters"}),"\n",(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Parameter"}),(0,i.jsx)("th",{children:"Type"}),(0,i.jsx)("th",{children:"Default value"})]})}),(0,i.jsxs)("tbody",{children:[(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"domainName"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"undefined"})})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"useSeparation"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"boolean"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"false"})})})]})]})]}),"\n",(0,i.jsx)(n.h4,{id:"returns",children:"Returns"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"SpeechConverterOnline"})}),"\n",(0,i.jsx)(n.h2,{id:"methods",children:"Methods"}),"\n",(0,i.jsx)(n.h3,{id:"getstatus",children:"getStatus()"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"getStatus(): string;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/e7ecee09619c371f2c7a38bb65d9a3fd55a16d86/src/SpeechConverterOnline.ts#L164",children:"SpeechConverterOnline.ts:164"})]}),"\n",(0,i.jsx)(n.p,{children:"Is not implemented for this implementation of SpeechConverter"}),"\n",(0,i.jsx)(n.h4,{id:"returns-1",children:"Returns"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})}),"\n",(0,i.jsx)(n.h4,{id:"throws",children:"Throws"}),"\n",(0,i.jsx)(n.p,{children:"Method not implemented"}),"\n",(0,i.jsx)(n.h4,{id:"implementation-of",children:"Implementation of"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface",children:(0,i.jsx)(n.code,{children:"SpeechConverterInterface"})}),".",(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface#getstatus",children:(0,i.jsx)(n.code,{children:"getStatus"})})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"gettextlog",children:"getTextLog()"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"getTextLog(): string[];\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/e7ecee09619c371f2c7a38bb65d9a3fd55a16d86/src/SpeechConverterOnline.ts#L231",children:"SpeechConverterOnline.ts:231"})]}),"\n",(0,i.jsx)(n.p,{children:"takes the array of objects that hold the transcribed logs\nand converts it into a string of the following format\nTimestamp: Transcribed text"}),"\n",(0,i.jsx)(n.h4,{id:"returns-2",children:"Returns"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"string"}),"[]"]}),"\n",(0,i.jsx)(n.p,{children:"Returns an array of transcribed logs"}),"\n",(0,i.jsx)(n.h4,{id:"implementation-of-1",children:"Implementation of"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface",children:(0,i.jsx)(n.code,{children:"SpeechConverterInterface"})}),".",(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface#gettextlog",children:(0,i.jsx)(n.code,{children:"getTextLog"})})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"gettranscribed",children:"getTranscribed()"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"getTranscribed(): string;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/e7ecee09619c371f2c7a38bb65d9a3fd55a16d86/src/SpeechConverterOnline.ts#L154",children:"SpeechConverterOnline.ts:154"})]}),"\n",(0,i.jsx)(n.p,{children:"Retrieves the latest transcription result from the Whisper model and logs it."}),"\n",(0,i.jsx)(n.p,{children:"This method calls the underlying Whisper API to obtain the most recently\ntranscribed text. If any text has been returned from whisper, it logs it."}),"\n",(0,i.jsx)(n.h4,{id:"returns-3",children:"Returns"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"The transcribed text from the current audio chunk."}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"implementation-of-2",children:"Implementation of"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface",children:(0,i.jsx)(n.code,{children:"SpeechConverterInterface"})}),".",(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface#gettranscribed",children:(0,i.jsx)(n.code,{children:"getTranscribed"})})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"getuseseparation",children:"getUseSeparation()"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"getUseSeparation(): boolean;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/e7ecee09619c371f2c7a38bb65d9a3fd55a16d86/src/SpeechConverterOnline.ts#L37",children:"SpeechConverterOnline.ts:37"})]}),"\n",(0,i.jsx)(n.p,{children:"Get whether speaker separation is enabled"}),"\n",(0,i.jsx)(n.h4,{id:"returns-4",children:"Returns"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"boolean"})}),"\n",(0,i.jsx)(n.p,{children:"true if using separation endpoint"}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"init",children:"init()"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"init(modelPath, lang): Promise`<void>`;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/e7ecee09619c371f2c7a38bb65d9a3fd55a16d86/src/SpeechConverterOnline.ts#L46",children:"SpeechConverterOnline.ts:46"})]}),"\n",(0,i.jsx)(n.p,{children:"Is not implemented for this version, throws an error if called"}),"\n",(0,i.jsx)(n.h4,{id:"parameters-1",children:"Parameters"}),"\n",(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Parameter"}),(0,i.jsx)("th",{children:"Type"})]})}),(0,i.jsxs)("tbody",{children:[(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"modelPath"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"lang"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})})]})]})]}),"\n",(0,i.jsx)(n.h4,{id:"returns-5",children:"Returns"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"Promise"}),"<",(0,i.jsx)(n.code,{children:"void"}),">"]}),"\n",(0,i.jsx)(n.h4,{id:"implementation-of-3",children:"Implementation of"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface",children:(0,i.jsx)(n.code,{children:"SpeechConverterInterface"})}),".",(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface#init",children:(0,i.jsx)(n.code,{children:"init"})})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"startlistening",children:"startListening()"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"startListening(): void;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/e7ecee09619c371f2c7a38bb65d9a3fd55a16d86/src/SpeechConverterOnline.ts#L63",children:"SpeechConverterOnline.ts:63"})]}),"\n",(0,i.jsx)(n.p,{children:"Starts listening to the user's microphone input, collects audio chunks,\nand feeds them into the backend for transcription in real time."}),"\n",(0,i.jsxs)(n.p,{children:["The method continuously gathers small chunks from ",(0,i.jsx)(n.code,{children:"AudioInputHandler"}),",\ncombines them into fixed-size blocks and sends them to the model for inference."]}),"\n",(0,i.jsx)(n.h4,{id:"returns-6",children:"Returns"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"void"})}),"\n",(0,i.jsx)(n.h4,{id:"throws-1",children:"Throws"}),"\n",(0,i.jsx)(n.p,{children:"Throws if fetch status is not 200"}),"\n",(0,i.jsx)(n.h4,{id:"throws-2",children:"Throws"}),"\n",(0,i.jsx)(n.p,{children:"Throws if Promise fails to resolve"}),"\n",(0,i.jsx)(n.h4,{id:"implementation-of-4",children:"Implementation of"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface",children:(0,i.jsx)(n.code,{children:"SpeechConverterInterface"})}),".",(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface#startlistening",children:(0,i.jsx)(n.code,{children:"startListening"})})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"stoplistening",children:"stopListening()"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"stopListening(): void;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/e7ecee09619c371f2c7a38bb65d9a3fd55a16d86/src/SpeechConverterOnline.ts#L142",children:"SpeechConverterOnline.ts:142"})]}),"\n",(0,i.jsx)(n.p,{children:"Stops the audio input stream and halts the real-time transcription process."}),"\n",(0,i.jsxs)(n.p,{children:["This should be called after ",(0,i.jsx)(n.code,{children:"startListening()"})," to stop capturing microphone input\nand free up system audio resources."]}),"\n",(0,i.jsx)(n.h4,{id:"returns-7",children:"Returns"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"void"})}),"\n",(0,i.jsx)(n.h4,{id:"implementation-of-5",children:"Implementation of"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface",children:(0,i.jsx)(n.code,{children:"SpeechConverterInterface"})}),".",(0,i.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/interfaces/SpeechConverterInterface#stoplistening",children:(0,i.jsx)(n.code,{children:"stopListening"})})]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);