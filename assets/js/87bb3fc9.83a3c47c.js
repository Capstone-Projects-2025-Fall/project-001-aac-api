"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[3335],{28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>c});var i=s(96540);const t={},r=i.createContext(t);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(r.Provider,{value:n},e.children)}},67326:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"api-specification/classes/AudioInputHandler","title":"AudioInputHandler","description":"aac-voice-api","source":"@site/docs/api-specification/classes/AudioInputHandler.md","sourceDirName":"api-specification/classes","slug":"/api-specification/classes/AudioInputHandler","permalink":"/project-001-aac-api/docs/api-specification/classes/AudioInputHandler","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/edit/main/documentation/docs/api-specification/classes/AudioInputHandler.md","tags":[],"version":"current","lastUpdatedBy":"Hena Patel","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"AACVoiceAPI","permalink":"/project-001-aac-api/docs/api-specification/classes/AACVoiceAPI"},"next":{"title":"CommandConverter","permalink":"/project-001-aac-api/docs/api-specification/classes/CommandConverter"}}');var t=s(74848),r=s(28453);const a={},c=void 0,o={},d=[{value:"Constructors",id:"constructors",level:2},{value:"Constructor",id:"constructor",level:3},{value:"Parameters",id:"parameters",level:4},{value:"Returns",id:"returns",level:4},{value:"Properties",id:"properties",level:2},{value:"isListening",id:"islistening",level:3},{value:"Methods",id:"methods",level:2},{value:"getSampleRate()",id:"getsamplerate",level:3},{value:"Returns",id:"returns-1",level:4},{value:"startListening()",id:"startlistening",level:3},{value:"Returns",id:"returns-2",level:4},{value:"stopListening()",id:"stoplistening",level:3},{value:"Returns",id:"returns-3",level:4}];function l(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/",children:(0,t.jsx)(n.strong,{children:"aac-voice-api"})})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/41187bee5e403b9cc4538359432d03a80f2624ae/src/AudioInputHandler.ts#L12",children:"AudioInputHandler.ts:12"})]}),"\n",(0,t.jsx)(n.p,{children:"AudioInputHandler is a microphone input handler that:\nCaptures audio from the user\u2019s microphone.\nProcesses audio in chunks (Float32Array).\nSends those chunks to a callback function for further processing.\nIt also provides start/stop control and exposes the audio sample rate."}),"\n",(0,t.jsx)(n.h2,{id:"constructors",children:"Constructors"}),"\n",(0,t.jsx)(n.h3,{id:"constructor",children:"Constructor"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:"new AudioInputHandler(onAudioChunk): AudioInputHandler;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/41187bee5e403b9cc4538359432d03a80f2624ae/src/AudioInputHandler.ts#L33",children:"AudioInputHandler.ts:33"})]}),"\n",(0,t.jsx)(n.p,{children:"Creates a new AudioInputHandler."}),"\n",(0,t.jsx)(n.h4,{id:"parameters",children:"Parameters"}),"\n",(0,t.jsxs)("table",{children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Parameter"}),(0,t.jsx)("th",{children:"Type"}),(0,t.jsx)("th",{children:"Description"})]})}),(0,t.jsx)("tbody",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"onAudioChunk"})})}),(0,t.jsx)("td",{children:(0,t.jsxs)(n.p,{children:["(",(0,t.jsx)(n.code,{children:"chunk"}),") => ",(0,t.jsx)(n.code,{children:"void"})]})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:"A callback function that is called whenever\nan audio chunk is captured. Receives a Float32Array\ncontaining the audio samples."})})]})})]}),"\n",(0,t.jsx)(n.h4,{id:"returns",children:"Returns"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"AudioInputHandler"})}),"\n",(0,t.jsx)(n.h2,{id:"properties",children:"Properties"}),"\n",(0,t.jsx)(n.h3,{id:"islistening",children:"isListening"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:"isListening: boolean = false;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/41187bee5e403b9cc4538359432d03a80f2624ae/src/AudioInputHandler.ts#L21",children:"AudioInputHandler.ts:21"})]}),"\n",(0,t.jsx)(n.p,{children:"Flag that checks if startListening has already been called"}),"\n",(0,t.jsx)(n.h2,{id:"methods",children:"Methods"}),"\n",(0,t.jsx)(n.h3,{id:"getsamplerate",children:"getSampleRate()"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:"getSampleRate(): number;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/41187bee5e403b9cc4538359432d03a80f2624ae/src/AudioInputHandler.ts#L43",children:"AudioInputHandler.ts:43"})]}),"\n",(0,t.jsx)(n.p,{children:"Returns the sample rate of the audio context."}),"\n",(0,t.jsx)(n.h4,{id:"returns-1",children:"Returns"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"number"})}),"\n",(0,t.jsxs)(n.p,{children:["The sample rate in Hz, or ",(0,t.jsx)(n.code,{children:"undefined"})," if the audio context is not initialized."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"startlistening",children:"startListening()"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:"startListening(): Promise`<void>`;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/41187bee5e403b9cc4538359432d03a80f2624ae/src/AudioInputHandler.ts#L57",children:"AudioInputHandler.ts:57"})]}),"\n",(0,t.jsx)(n.p,{children:"Starts capturing audio from the user's microphone."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Prompts the user for microphone permissions."}),"\n",(0,t.jsx)(n.li,{children:"Creates an AudioContext and a ScriptProcessorNode to process audio in chunks."}),"\n",(0,t.jsxs)(n.li,{children:["Calls the ",(0,t.jsx)(n.code,{children:"onAudioChunk"})," callback with a Float32Array for each audio buffer."]}),"\n",(0,t.jsx)(n.li,{children:"Handles errors such as permission denial or missing microphone hardware."}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"returns-2",children:"Returns"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"Promise"}),"<",(0,t.jsx)(n.code,{children:"void"}),">"]}),"\n",(0,t.jsx)(n.p,{children:"A Promise that resolves when listening has started."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"stoplistening",children:"stopListening()"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:"stopListening(): void;\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/41187bee5e403b9cc4538359432d03a80f2624ae/src/AudioInputHandler.ts#L111",children:"AudioInputHandler.ts:111"})]}),"\n",(0,t.jsx)(n.p,{children:"Stops capturing audio from the microphone and cleans up resources."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Disconnects the ScriptProcessorNode from the audio graph."}),"\n",(0,t.jsx)(n.li,{children:"Closes the AudioContext."}),"\n",(0,t.jsx)(n.li,{children:"Stops all tracks of the MediaStream."}),"\n",(0,t.jsxs)(n.li,{children:["Updates the ",(0,t.jsx)(n.code,{children:"isListening"})," flag to ",(0,t.jsx)(n.code,{children:"false"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"returns-3",children:"Returns"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"void"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}}}]);