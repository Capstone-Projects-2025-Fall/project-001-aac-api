"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[1165],{28453:(e,n,s)=>{s.d(n,{R:()=>d,x:()=>o});var i=s(96540);const t={},r=i.createContext(t);function d(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:d(e.components),i.createElement(r.Provider,{value:n},e.children)}},60065:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>d,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"api-specification/AudioInputHandler/classes/AudioInputHandler","title":"AudioInputHandler","description":"aac-voice-api","source":"@site/docs/api-specification/AudioInputHandler/classes/AudioInputHandler.md","sourceDirName":"api-specification/AudioInputHandler/classes","slug":"/api-specification/AudioInputHandler/classes/AudioInputHandler","permalink":"/project-001-aac-api/docs/api-specification/AudioInputHandler/classes/AudioInputHandler","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/edit/main/documentation/docs/api-specification/AudioInputHandler/classes/AudioInputHandler.md","tags":[],"version":"current","lastUpdatedBy":"Michael Colbert","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"AudioInputHandler","permalink":"/project-001-aac-api/docs/api-specification/AudioInputHandler/"},"next":{"title":"CommandConverter","permalink":"/project-001-aac-api/docs/api-specification/CommandConverter/"}}');var t=s(74848),r=s(28453);const d={},o=void 0,c={},a=[{value:"Constructors",id:"constructors",level:2},{value:"Constructor",id:"constructor",level:3},{value:"Parameters",id:"parameters",level:4},{value:"Returns",id:"returns",level:4},{value:"Properties",id:"properties",level:2},{value:"isListening",id:"islistening",level:3},{value:"Methods",id:"methods",level:2},{value:"getSampleRate()",id:"getsamplerate",level:3},{value:"Returns",id:"returns-1",level:4},{value:"startListening()",id:"startlistening",level:3},{value:"Returns",id:"returns-2",level:4},{value:"stopListening()",id:"stoplistening",level:3},{value:"Returns",id:"returns-3",level:4}];function l(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"/project-001-aac-api/docs/api-specification/",children:(0,t.jsx)(n.strong,{children:"aac-voice-api"})})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h1,{id:"class-audioinputhandler",children:"Class: AudioInputHandler"}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/681b1bef6f4d46f8f7614169d87f151ce783205a/src/AudioInputHandler.ts#L12",children:"AudioInputHandler.ts:12"})]}),"\n",(0,t.jsx)(n.p,{children:"AudioInputHandler is a microphone input handler that:\nCaptures audio from the user\u2019s microphone.\nProcesses audio in chunks (Float32Array).\nSends those chunks to a callback function for further processing.\nIt also provides start/stop control and exposes the audio sample rate."}),"\n",(0,t.jsx)(n.h2,{id:"constructors",children:"Constructors"}),"\n",(0,t.jsx)(n.h3,{id:"constructor",children:"Constructor"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"new AudioInputHandler"}),"(",(0,t.jsx)(n.code,{children:"onAudioChunk"}),"): ",(0,t.jsx)(n.code,{children:"AudioInputHandler"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/681b1bef6f4d46f8f7614169d87f151ce783205a/src/AudioInputHandler.ts#L33",children:"AudioInputHandler.ts:33"})]}),"\n",(0,t.jsx)(n.p,{children:"Creates a new AudioInputHandler."}),"\n",(0,t.jsx)(n.h4,{id:"parameters",children:"Parameters"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Parameter"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsx)(n.tbody,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"onAudioChunk"})}),(0,t.jsxs)(n.td,{children:["(",(0,t.jsx)(n.code,{children:"chunk"}),") => ",(0,t.jsx)(n.code,{children:"void"})]}),(0,t.jsx)(n.td,{children:"A callback function that is called whenever an audio chunk is captured. Receives a Float32Array containing the audio samples."})]})})]}),"\n",(0,t.jsx)(n.h4,{id:"returns",children:"Returns"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"AudioInputHandler"})}),"\n",(0,t.jsx)(n.h2,{id:"properties",children:"Properties"}),"\n",(0,t.jsx)(n.h3,{id:"islistening",children:"isListening"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"isListening"}),": ",(0,t.jsx)(n.code,{children:"boolean"})," = ",(0,t.jsx)(n.code,{children:"false"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/681b1bef6f4d46f8f7614169d87f151ce783205a/src/AudioInputHandler.ts#L21",children:"AudioInputHandler.ts:21"})]}),"\n",(0,t.jsx)(n.p,{children:"Flag that checks if startListening has already been called"}),"\n",(0,t.jsx)(n.h2,{id:"methods",children:"Methods"}),"\n",(0,t.jsx)(n.h3,{id:"getsamplerate",children:"getSampleRate()"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"getSampleRate"}),"(): ",(0,t.jsx)(n.code,{children:"number"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/681b1bef6f4d46f8f7614169d87f151ce783205a/src/AudioInputHandler.ts#L43",children:"AudioInputHandler.ts:43"})]}),"\n",(0,t.jsx)(n.p,{children:"Returns the sample rate of the audio context."}),"\n",(0,t.jsx)(n.h4,{id:"returns-1",children:"Returns"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"number"})}),"\n",(0,t.jsxs)(n.p,{children:["The sample rate in Hz, or ",(0,t.jsx)(n.code,{children:"undefined"})," if the audio context is not initialized."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"startlistening",children:"startListening()"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"startListening"}),"(): ",(0,t.jsx)(n.code,{children:"Promise"}),"<",(0,t.jsx)(n.code,{children:"void"}),">"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/681b1bef6f4d46f8f7614169d87f151ce783205a/src/AudioInputHandler.ts#L57",children:"AudioInputHandler.ts:57"})]}),"\n",(0,t.jsx)(n.p,{children:"Starts capturing audio from the user's microphone."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Prompts the user for microphone permissions."}),"\n",(0,t.jsx)(n.li,{children:"Creates an AudioContext and a ScriptProcessorNode to process audio in chunks."}),"\n",(0,t.jsxs)(n.li,{children:["Calls the ",(0,t.jsx)(n.code,{children:"onAudioChunk"})," callback with a Float32Array for each audio buffer."]}),"\n",(0,t.jsx)(n.li,{children:"Handles errors such as permission denial or missing microphone hardware."}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"returns-2",children:"Returns"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"Promise"}),"<",(0,t.jsx)(n.code,{children:"void"}),">"]}),"\n",(0,t.jsx)(n.p,{children:"A Promise that resolves when listening has started."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"stoplistening",children:"stopListening()"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"stopListening"}),"(): ",(0,t.jsx)(n.code,{children:"void"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Defined in: ",(0,t.jsx)(n.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/blob/681b1bef6f4d46f8f7614169d87f151ce783205a/src/AudioInputHandler.ts#L111",children:"AudioInputHandler.ts:111"})]}),"\n",(0,t.jsx)(n.p,{children:"Stops capturing audio from the microphone and cleans up resources."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Disconnects the ScriptProcessorNode from the audio graph."}),"\n",(0,t.jsx)(n.li,{children:"Closes the AudioContext."}),"\n",(0,t.jsx)(n.li,{children:"Stops all tracks of the MediaStream."}),"\n",(0,t.jsxs)(n.li,{children:["Updates the ",(0,t.jsx)(n.code,{children:"isListening"})," flag to ",(0,t.jsx)(n.code,{children:"false"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"returns-3",children:"Returns"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"void"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}}}]);