"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[9238],{28453:(e,i,n)=>{n.d(i,{R:()=>s,x:()=>r});var t=n(96540);const o={},a=t.createContext(o);function s(e){const i=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function r(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(a.Provider,{value:i},e.children)}},54730:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"api-specification/api-specification","title":"api-specification","description":"aac-voice-api","source":"@site/docs/api-specification/api-specification.md","sourceDirName":"api-specification","slug":"/api-specification/","permalink":"/project-001-aac-api/docs/api-specification/","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/edit/main/documentation/docs/api-specification/api-specification.md","tags":[],"version":"current","lastUpdatedBy":"Michael Colbert","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Testing","permalink":"/project-001-aac-api/docs/testing/testing-document"},"next":{"title":"AACVoiceAPI","permalink":"/project-001-aac-api/docs/api-specification/AACVoiceAPI/"}}');var o=n(74848),a=n(28453);const s={},r=void 0,c={},l=[{value:"Getting Started",id:"getting-started",level:2},{value:"Installing the API",id:"installing-the-api",level:3},{value:"Example",id:"example",level:2},{value:"Project Abstract",id:"project-abstract",level:2},{value:"High Level Requirement",id:"high-level-requirement",level:2},{value:"Conceptual Design",id:"conceptual-design",level:2},{value:"Background",id:"background",level:2},{value:"Collaborators",id:"collaborators",level:2}];function d(e){const i={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",hr:"hr",img:"img",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(i.p,{children:(0,o.jsx)(i.strong,{children:"aac-voice-api"})}),"\n",(0,o.jsx)(i.hr,{}),"\n",(0,o.jsxs)("div",{align:"center",children:[(0,o.jsx)(i.h1,{id:"aaccommodate-api",children:"AACcommodate API"}),(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.a,{href:"https://temple-cis-projects-in-cs.atlassian.net/jira/software/c/projects/AAC/issues?jql=project%20%3D%20%22AAC%22%20ORDER%20BY%20created%20DESC",children:(0,o.jsx)(i.img,{src:"https://img.shields.io/badge/Report%20Issues-Jira-0052CC?style=flat&logo=jira-software",alt:"Report Issue on Jira"})}),"\n",(0,o.jsx)(i.a,{href:"https://github.com/Capstone-Projects-2025-Fall/project-001-aac-api/actions/workflows/deploy.yml",children:(0,o.jsx)(i.img,{src:"https://github.com/ApplebaumIan/tu-cis-4398-docs-template/actions/workflows/deploy.yml/badge.svg",alt:"Deploy Docs"})}),"\n",(0,o.jsx)(i.a,{href:"https://capstone-projects-2025-fall.github.io/project-001-aac-api/docs/requirements/system-overview",children:(0,o.jsx)(i.img,{src:"https://img.shields.io/badge/-Documentation%20Website-brightgreen",alt:"Documentation Website Link"})})]})]}),"\n",(0,o.jsx)(i.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,o.jsx)(i.h3,{id:"installing-the-api",children:"Installing the API"}),"\n",(0,o.jsxs)(i.p,{children:["How to download the ",(0,o.jsx)(i.a,{href:"https://www.npmjs.com/package/aac-voice-api",children:"NPM package"})," to use in your own project."]}),"\n",(0,o.jsx)(i.p,{children:"To install the npm package in your project, open a terminal and enter the following command:"}),"\n",(0,o.jsx)(i.p,{children:(0,o.jsx)(i.code,{children:"npm install aac-voice-api"})}),"\n",(0,o.jsxs)(i.p,{children:["Once you have installed the npm package, you'll want to add the Whisper model to your project. The link to the model can be found ",(0,o.jsx)(i.a,{href:"https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin",children:"here"}),"\nThen, using vite, add the following lines to your project code:"]}),"\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.code,{children:"'Cross-Origin-Opener-Policy': 'same-origin',"}),"\n",(0,o.jsx)(i.code,{children:"'Cross-Origin-Embedder-Policy': 'require-corp',"})]}),"\n",(0,o.jsxs)(i.p,{children:["To see a sample of the API in another project, go to ",(0,o.jsx)(i.a,{href:"https://github.com/Russo903/aac-voice-api-milestone-demo-1.git",children:"this repository"})," and clone it locally. Run the following commands:"]}),"\n",(0,o.jsx)(i.p,{children:(0,o.jsx)(i.code,{children:"npm install"})}),"\n",(0,o.jsx)(i.p,{children:(0,o.jsx)(i.code,{children:"npm run dev"})}),"\n",(0,o.jsx)(i.p,{children:"You are now hosting the game locally."}),"\n",(0,o.jsx)(i.p,{children:"Here is an example of how to add game commands to your project."}),"\n",(0,o.jsx)(i.h2,{id:"example",children:"Example"}),"\n",(0,o.jsx)(i.pre,{children:(0,o.jsx)(i.code,{className:"language-ts",children:'import { AACVoiceAPI } from \'aac-voice-api\';\n\n// Create an instance of the voice API\nconst voice = new AACVoiceAPI();\n\n// Add a voice command\nvoice.addVoiceCommand(\n  name: "jump",\n  action: () => console.log("player jumped"),\n);\n\n// Initialize the API\n// Whisper Models can be found at https://huggingface.co/ggerganov/whisper.cpp/tree/main\nvoice.initiate("url", "en");\n\n// Start listening for voice commands\nvoice.start();\n'})}),"\n",(0,o.jsx)(i.h2,{id:"project-abstract",children:"Project Abstract"}),"\n",(0,o.jsx)(i.p,{children:"This application programming interface (API) supports AAC games. The API allows users to play AAC games like StoryQuest through external AAC board interaction, rather than relying on an embedded AAC board in the game. Users can relay game inputs by either speaking verbally or speaking through the board. The API will enable audio-controlled games, which will promote social and communication skills in children who use AAC devices by enabling AAC users to play games alongside non-AAC users."}),"\n",(0,o.jsx)(i.h2,{id:"high-level-requirement",children:"High Level Requirement"}),"\n",(0,o.jsx)(i.p,{children:"The API must convert voice input into game action and be able to define game commands. Users can play previous AAC games using our API. The API must be able to interpret synonyms of commands as valid inputs. The API should allow game developers to update a list of known game commands."}),"\n",(0,o.jsx)(i.h2,{id:"conceptual-design",children:"Conceptual Design"}),"\n",(0,o.jsx)(i.p,{children:'The proposed solution is a client side Typescript API designed for integration into new or existing web based games for Augmentative and Alternative Communication (AAC) user\'s. The API leverages standard browser technologies to ensure wide compatibility with most machines. The core audio processing pipeline uses Web Speech API for speech to text. Web Audio API and RNNoise will be used to clean the audio. This process isolates the users AAC device from ambient sound and other voices. The API is structured for reusability. A game developer integrates the library by initializing with a config object. THe object serves as a developer defined dictionary, mapping voice commands (eg "jump") to specific callback functions within the games existing code.'}),"\n",(0,o.jsx)(i.h2,{id:"background",children:"Background"}),"\n",(0,o.jsx)(i.p,{children:"Augmentative and Alternate Communication (AAC) devices provide essential communication capabilities for individuals with significant speech impairments resulting from conditions such as Autism Spectrum Disorder, Cerebral Palsy, or ALS. While effective for structured expression, these devices often present challenges in the fast paced, interactive context of video games. This technological gap can lead to frustrating user experience and social exclusion for AAC users. Current solutions for this issue generally look like this. Involving in game, simulated AAC boards, which require users to learn a new, game specific interface rather than using their own familiar device. This project addresses these limitations by developing a reusable software tool, a developer focused API, rather than a single, standalone game. The goal is to provide a solution that game developers can integrate into any new or exisiting web based application. This approach improves upon the current model by allowing direct input from the users personal devices."}),"\n",(0,o.jsx)(i.h2,{id:"collaborators",children:"Collaborators"}),"\n",(0,o.jsx)("div",{align:"center",children:(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.a,{href:"https://github.com/ApplebaumIan",children:"Ian Tyler Applebaum"})," \u2022 ",(0,o.jsx)(i.a,{href:"https://github.com/leekd99",children:"Kyle Dragon Lee"})," \u2022 ",(0,o.jsx)(i.a,{href:"https://github.com/HolyGodEze",children:"Tam Trang"})," \u2022 ",(0,o.jsx)(i.a,{href:"https://github.com/colbert95",children:"Michael Colbert"})," \u2022 ",(0,o.jsx)(i.a,{href:"https://github.com/jesshutchison",children:"Jessica Hutchison"})," \u2022 ",(0,o.jsx)(i.a,{href:"https://github.com/Russo903",children:"Gino Russo"})," \u2022 ",(0,o.jsx)(i.a,{href:"https://github.com/Hena3124",children:"Hena Patel"})]})})]})}function p(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,o.jsx)(i,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);